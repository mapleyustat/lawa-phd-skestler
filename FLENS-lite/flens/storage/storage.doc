==title:Storage Schemes{flens::storage}==

BLAS provides linear algebra routines for different matrix types: triangular, symmetric, hermitian and general (i.e., non-square or unsymmetric). Storage of elements can be organized following different schemes â€“ in the following denoted as storage schemes. What particular storage scheme is favorable depends on the matrix structure as well as the numerical methods operating on the matrix. While in some cases compact storage of a matrix is essential, in others it is crucial to have fast access to single elements, whole rows or columns or to operate efficiently on matrix slices.

==section:Storage Scheme Implementations in FLENS==

==subsection: Array (Storage Scheme for Dense Vectors)#Array==

Vector elements are stored linearly in memory separated from each other by a constant [stride]. 

Available Implementations are:
==toc:array/==

==subsection: Full Storage (Storage Scheme for Dense Matrices)#FullStorage==
In the full storage scheme, all [$m \cdot n$] elements of a [$m \times n$] matrix are stored in an array.  The storage is said to be [row major] or [column major] if elements are stored row or column wise respectively.
==toc:fullstorage/==

==subsection: Band Storage (Storage Scheme for Dense Matrices)==
On the TODO list

==subsection: Packed Storage (Storage Scheme for Dense Matrices)==
On the TODO list


==section:Difference between Storage Schemes and Matrix/Vector Types#StorageSchemeAndMatrixTypes==

It is important to point out the difference between storage schemes and
matrix types. Each storage scheme merely defines a certain format specifying
how to store matrix elements in memory. However, the storage scheme itself
does not specify a particular matrix type. For illustration consider the
general matrix
==latex==
\[
   A =\begin{pmatrix}
      a_{1,1} & a_{1,2} & a_{1,3} &       0 \\
      a_{2,1} & a_{2,2} & a_{2,3} & a_{2,4} \\
            0 & a_{3,2} & a_{3,3} & a_{3,4} \\
            0 &       0 & a_{4,3} & a_{4,4} \\    
      \end{pmatrix}.
\]
====
The very same storage scheme used to store elements of [$A$] can be used to
represent symmetric, hermitian or triangular matrices.  Referencing only
elements from the storage scheme belonging to either the upper or lower
triangular part allows to represent symmetric matrices (elements that are
actually required to be stored stored in memory are indicated red):
==latex==
$ S_U=\begin{pmatrix}
      \textcolor{red}{a_{1,1}} & \textcolor{red}{a_{1,2}} & \textcolor{red}{a_{1,3}} &       0 \\
                      a_{1,2}  & \textcolor{red}{a_{2,2}} & \textcolor{red}{a_{2,3}} & \textcolor{red}{a_{2,4}} \\
                      a_{1,3}  &                 a_{2,3}  & \textcolor{red}{a_{3,3}} & \textcolor{red}{a_{3,4}} \\
                      0        &                 a_{2,4}  &                 a_{3,4}  & \textcolor{red}{a_{4,4}} \\    
      \end{pmatrix}$
&
    or
&
$ S_L=\begin{pmatrix}
      \textcolor{red}{a_{1,1}} &                 a_{2,1}  &                       0  &                       0  \\
      \textcolor{red}{a_{2,1}} & \textcolor{red}{a_{2,2}} &                 a_{3,2}  &                       0  \\
                            0  & \textcolor{red}{a_{3,2}} & \textcolor{red}{a_{3,3}} &                 a_{4,3}  \\
                            0  &                       0  & \textcolor{red}{a_{4,3}} & \textcolor{red}{a_{4,4}} \\    
      \end{pmatrix}$. \\
====
Analogously, the scheme can be interpreted to represent upper or lower
triangular matrices.  Triangular matrices can further be assumed to be
unit triangular such that diagonal elements are actually not referenced.
In connection with the [LU] decomposition it is in particular useful to
interpret the storage scheme of a general matrix also as 
==latex==
$ U= \begin{pmatrix}
      \textcolor{red}{a_{1,1}} & \textcolor{red}{a_{1,2}} & \textcolor{red}{a_{1,3}} &                       0  \\
                            0  & \textcolor{red}{a_{2,2}} & \textcolor{red}{a_{2,3}} & \textcolor{red}{a_{2,4}} \\
                            0  &                       0  & \textcolor{red}{a_{3,3}} & \textcolor{red}{a_{3,4}} \\
                            0  &                       0  &                       0  & \textcolor{red}{a_{4,4}} \\    
      \end{pmatrix} $
&
       or 
&
$ L= \begin{pmatrix}
                            1  &                       0  &                       0  &       0 \\
      \textcolor{red}{a_{2,1}} &                       1  &                       0  &       0 \\
                            0  & \textcolor{red}{a_{3,2}} &                       1  &       0 \\
                            0  &                       0  & \textcolor{red}{a_{4,3}} &       1 \\    
      \end{pmatrix}$. \\
====
Recapitulating and simplifying one can note that --- in the sense of BLAS
and LAPACK --- matrix types are compositions of storage schemes together with
some additional informations specifying how to interpret these schemes.

With respect to software quality such a loose coupling between storage scheme
and matrix type is not optimal.  In FLENS {@flens/matrixtypes/matrix}{matrix}
and  {@flens/vectortypes/vector}{vector} classes firmly link these ideas together.

==section:Storage Schemes and Views (Slices)#Views==

In FLENS we call storage schemes referencing parts of other storage schemes
[views].  We adapted this term from data bases.  More details on how we
implemented views is given in the {@@concept::View}{concepts} section.

